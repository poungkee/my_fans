#!/usr/bin/env python3
"""
AI-Hub ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
"""

import json
import os
import logging
from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)
from torch.utils.data import Dataset
import warnings
warnings.filterwarnings('ignore')

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SentenceTypeDataset(Dataset):
    """ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜ ë°ì´í„°ì…‹"""

    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        label = self.labels[idx]

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

class SentenceTypeTrainer:
    """ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµê¸°"""

    def __init__(self, model_name: str = "beomi/KcELECTRA-base-v2022"):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.label_map = {}
        self.reverse_label_map = {}

    def load_aihub_data(self, data_path: str, sample_size: int = None) -> pd.DataFrame:
        """AI-Hub ë°ì´í„° ë¡œë“œ"""
        all_data = []

        # AI-Hub ë°ì´í„° íŒŒì¼ íŒ¨í„´
        patterns = [
            "TL_ë‰´ìŠ¤_ì‚¬íšŒ*.json",
            "TL_ë‰´ìŠ¤_ê¸ˆìœµ*.json",
            "TL_ë‰´ìŠ¤_ë¬¸í™”*.json",
            "TL_ë‰´ìŠ¤_ì •ì¹˜*.json",
            "TL_ë‰´ìŠ¤_ê²½ì œ*.json"
        ]

        for pattern in patterns:
            files = list(Path(data_path).glob(pattern))
            for file_path in files[:1]:  # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ 1ê°œ íŒŒì¼ë§Œ
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # ë°ì´í„° ì¶”ì¶œ
                    for doc in data.get('document', [])[:sample_size]:
                        for sentence in doc.get('sentence', []):
                            sentence_data = {
                                'text': sentence.get('form', ''),
                                'sentence_type': sentence.get('sentence_type', 'unknown')
                            }
                            if sentence_data['text'] and sentence_data['sentence_type'] != 'unknown':
                                all_data.append(sentence_data)

                    logger.info(f"ë¡œë“œ ì™„ë£Œ: {file_path.name} - {len(all_data)}ê°œ ë¬¸ì¥")

                except Exception as e:
                    logger.warning(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}")

        return pd.DataFrame(all_data)

    def prepare_data(self, df: pd.DataFrame) -> Tuple[List[str], List[int]]:
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        # ë¼ë²¨ ì •ê·œí™”
        label_mapping = {
            'ì‚¬ì‹¤í˜•-ì§„ìˆ ': 'ì‚¬ì‹¤í˜•',
            'ì‚¬ì‹¤í˜•-ì¸ìš©': 'ì‚¬ì‹¤í˜•',
            'ì¶”ë¡ í˜•-ì¶”ì¸¡': 'ì¶”ë¡ í˜•',
            'ì¶”ë¡ í˜•-ë¶„ì„': 'ì¶”ë¡ í˜•',
            'ì˜ˆì¸¡í˜•': 'ì˜ˆì¸¡í˜•',
            'ëŒ€í™”í˜•': 'ëŒ€í™”í˜•'
        }

        df['sentence_type'] = df['sentence_type'].map(
            lambda x: label_mapping.get(x, x)
        )

        # ì£¼ìš” ìœ í˜•ë§Œ í•„í„°ë§
        main_types = ['ì‚¬ì‹¤í˜•', 'ì¶”ë¡ í˜•', 'ì˜ˆì¸¡í˜•', 'ëŒ€í™”í˜•']
        df = df[df['sentence_type'].isin(main_types)]

        # ë¼ë²¨ ì¸ì½”ë”©
        unique_labels = sorted(df['sentence_type'].unique())
        self.label_map = {label: idx for idx, label in enumerate(unique_labels)}
        self.reverse_label_map = {idx: label for label, idx in self.label_map.items()}

        texts = df['text'].tolist()
        labels = [self.label_map[label] for label in df['sentence_type']]

        return texts, labels

    def train_model(
        self,
        train_texts: List[str],
        train_labels: List[int],
        val_texts: List[str],
        val_labels: List[int],
        output_dir: str = "./models/sentence_type_model",
        num_epochs: int = 3,
        batch_size: int = 16,
        learning_rate: float = 2e-5
    ):
        """ëª¨ë¸ í•™ìŠµ"""
        # í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ë¡œë“œ
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=len(self.label_map),
            ignore_mismatched_sizes=True
        )
        self.model.to(self.device)

        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = SentenceTypeDataset(train_texts, train_labels, self.tokenizer)
        val_dataset = SentenceTypeDataset(val_texts, val_labels, self.tokenizer)

        # í•™ìŠµ ì„¤ì •
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=num_epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_ratio=0.1,
            weight_decay=0.01,
            logging_dir=f'{output_dir}/logs',
            logging_steps=100,
            evaluation_strategy="steps",
            eval_steps=500,
            save_strategy="steps",
            save_steps=500,
            load_best_model_at_end=True,
            metric_for_best_model="eval_loss",
            greater_is_better=False,
            save_total_limit=2,
            remove_unused_columns=False,
            push_to_hub=False,
            report_to="none",
            seed=42
        )

        # í•™ìŠµê¸° ìƒì„±
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
        )

        # í•™ìŠµ ì‹œì‘
        logger.info("ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        train_result = trainer.train()

        # ëª¨ë¸ ì €ì¥
        trainer.save_model()
        self.tokenizer.save_pretrained(output_dir)

        # ë¼ë²¨ ë§µ ì €ì¥
        with open(f"{output_dir}/label_map.json", 'w', encoding='utf-8') as f:
            json.dump({
                'label_map': self.label_map,
                'reverse_label_map': self.reverse_label_map
            }, f, ensure_ascii=False, indent=2)

        return train_result

    def evaluate_model(self, test_texts: List[str], test_labels: List[int]) -> Dict:
        """ëª¨ë¸ í‰ê°€"""
        if not self.model:
            raise ValueError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        self.model.eval()
        predictions = []

        with torch.no_grad():
            for text in test_texts:
                inputs = self.tokenizer(
                    text,
                    truncation=True,
                    padding=True,
                    max_length=512,
                    return_tensors='pt'
                ).to(self.device)

                outputs = self.model(**inputs)
                pred = torch.argmax(outputs.logits, dim=-1)
                predictions.append(pred.cpu().numpy()[0])

        # í‰ê°€ ì§€í‘œ ê³„ì‚°
        accuracy = accuracy_score(test_labels, predictions)
        report = classification_report(
            test_labels,
            predictions,
            target_names=list(self.label_map.keys()),
            output_dict=True
        )

        return {
            'accuracy': accuracy,
            'classification_report': report
        }

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ AI-Hub ë°ì´í„°ë¡œ ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘!")

    # í•™ìŠµê¸° ì´ˆê¸°í™”
    trainer = SentenceTypeTrainer()

    # ë°ì´í„° ê²½ë¡œ ì„¤ì •
    data_paths = [
        "/Users/hodduk/Downloads/ai_hub_data",
        "/tmp/ai_hub_data",
        "./data"
    ]

    data_path = None
    for path in data_paths:
        if os.path.exists(path):
            data_path = path
            break

    if not data_path:
        logger.error("AI-Hub ë°ì´í„° ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return

    logger.info("=== ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")

    # ë°ì´í„° ë¡œë“œ
    logger.info(f"AI-Hub ë°ì´í„° ë¡œë”© ì¤‘... (ê²½ë¡œ: {data_path})")
    df = trainer.load_aihub_data(data_path, sample_size=1000)

    if df.empty:
        logger.error("ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return

    # ë°ì´í„° ì¤€ë¹„
    logger.info(f"ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(df)}ê°œ ë¬¸ì¥")
    texts, labels = trainer.prepare_data(df)

    # ë°ì´í„° ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(
        texts, labels, test_size=0.2, random_state=42, stratify=labels
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )

    logger.info(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(X_val)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ")

    # ëª¨ë¸ í•™ìŠµ
    trainer.train_model(
        X_train, y_train,
        X_val, y_val,
        num_epochs=3,
        batch_size=8
    )

    # ëª¨ë¸ í‰ê°€
    logger.info("ëª¨ë¸ í‰ê°€ ì¤‘...")
    results = trainer.evaluate_model(X_test, y_test)

    logger.info(f"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {results['accuracy']:.4f}")
    logger.info("ë¶„ë¥˜ ë³´ê³ ì„œ:")
    for label, metrics in results['classification_report'].items():
        if label not in ['accuracy', 'macro avg', 'weighted avg']:
            logger.info(f"  {label}: precision={metrics['precision']:.3f}, recall={metrics['recall']:.3f}, f1={metrics['f1-score']:.3f}")

    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ ./models/sentence_type_modelì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()