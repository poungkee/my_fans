"""
âš ï¸ ì´ íŒŒì¼ì€ ë” ì´ìƒ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤ âš ï¸

Airflow â†’ Node.js ìŠ¤ì¼€ì¤„ëŸ¬(backend/scheduler)ë¡œ ëŒ€ì²´ë¨
Spark ML â†’ Simple Classifier API(backend/simple-classifier)ë¡œ ëŒ€ì²´ë¨

ì•„ë˜ ì½”ë“œëŠ” ì°¸ê³ ìš©ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
í•„ìš” ì‹œ ë³µêµ¬ ê°€ëŠ¥í•˜ë„ë¡ ì½”ë“œë¥¼ ì‚­ì œí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
"""

'''
# ===== ì•„ë˜ ì½”ë“œëŠ” ì£¼ì„ ì²˜ë¦¬ë¨ (Airflow ëŒ€ì²´) =====

"""
ì›ë³¸ ê¸°ì‚¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ DAG
raw_news_articles -> Spark ML ë¶„ë¥˜ -> news_articles
"""

from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.http.operators.http import SimpleHttpOperator
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

default_args = {
    'owner': 'fans',
    'depends_on_past': False,
    'start_date': datetime(2025, 10, 15),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=3),
}

dag = DAG(
    'raw_news_processing_pipeline',
    default_args=default_args,
    description='ì›ë³¸ ê¸°ì‚¬ë¥¼ Spark MLë¡œ ë¶„ë¥˜í•˜ì—¬ ê²€ì¦ëœ ê¸°ì‚¬ë¡œ ë³€í™˜',
    schedule_interval='*/10 * * * *',  # 10ë¶„ë§ˆë‹¤ ì‹¤í–‰
    catchup=False,
    tags=['news', 'classification', 'spark', 'raw'],
)

def check_raw_articles():
    """ì²˜ë¦¬í•  ì›ë³¸ ê¸°ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸"""
    import psycopg2
    import os

    logger.info("ğŸ” ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ì›ë³¸ ê¸°ì‚¬ í™•ì¸...")

    try:
        conn = psycopg2.connect(
            host=os.getenv('DB_HOST', 'postgres'),
            port=int(os.getenv('DB_PORT', 5432)),
            user=os.getenv('POSTGRES_USER', 'fans_user'),
            password=os.getenv('POSTGRES_PASSWORD', 'fans_password'),
            database=os.getenv('POSTGRES_DB', 'fans_db')
        )
        cursor = conn.cursor()

        cursor.execute("SELECT COUNT(*) FROM raw_news_articles WHERE processed = FALSE")
        count = cursor.fetchone()[0]

        cursor.close()
        conn.close()

        logger.info(f"ğŸ“Š ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ì›ë³¸ ê¸°ì‚¬: {count}ê°œ")

        if count == 0:
            logger.info("âœ… ì²˜ë¦¬í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            return "no_articles"
        else:
            logger.info(f"ğŸ”„ {count}ê°œ ê¸°ì‚¬ ì²˜ë¦¬ ì‹œì‘...")
            return f"found_{count}_articles"

    except Exception as e:
        logger.error(f"âŒ í™•ì¸ ì‹¤íŒ¨: {e}")
        raise

def process_articles():
    """Spark APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì›ë³¸ ê¸°ì‚¬ ì²˜ë¦¬"""
    import requests
    import os

    logger.info("ğŸš€ Spark ë¶„ë¥˜ API í˜¸ì¶œ...")

    try:
        response = requests.post(
            'http://classification-api:5000/process-raw-news',
            json={'limit': 100},
            timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        if response.status_code == 200:
            result = response.json()
            logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {result}")
            return result
        else:
            logger.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code} - {response.text}")
            raise Exception(f"API call failed with status {response.status_code}")

    except requests.exceptions.Timeout:
        logger.error("â° API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ")
        raise
    except Exception as e:
        logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise

def summarize_articles():
    """ì²˜ë¦¬ëœ ê¸°ì‚¬ì˜ AI ìš”ì•½ ìƒì„±"""
    import psycopg2
    import requests
    import os

    logger.info("ğŸ“ AI ìš”ì•½ ìƒì„± ì‹œì‘...")

    try:
        conn = psycopg2.connect(
            host=os.getenv('DB_HOST', 'postgres'),
            port=int(os.getenv('DB_PORT', 5432)),
            user=os.getenv('POSTGRES_USER', 'fans_user'),
            password=os.getenv('POSTGRES_PASSWORD', 'fans_password'),
            database=os.getenv('POSTGRES_DB', 'fans_db')
        )
        cursor = conn.cursor()

        # AI ìš”ì•½ì´ ì—†ëŠ” ê¸°ì‚¬ ì¡°íšŒ (ìµœê·¼ ì²˜ë¦¬ëœ ê²ƒë§Œ)
        cursor.execute("""
            SELECT id, content
            FROM news_articles
            WHERE ai_summary IS NULL
              AND content IS NOT NULL
              AND LENGTH(content) >= 100
            ORDER BY created_at DESC
            LIMIT 50
        """)

        articles = cursor.fetchall()

        if not articles:
            logger.info("âœ… ìš”ì•½í•  ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            cursor.close()
            conn.close()
            return "no_articles_to_summarize"

        logger.info(f"ğŸ“š {len(articles)}ê°œ ê¸°ì‚¬ ìš”ì•½ ìƒì„± ì¤‘...")

        summarized_count = 0

        for article_id, content in articles:
            try:
                # AI ìš”ì•½ API í˜¸ì¶œ
                response = requests.post(
                    'http://summarize-ai:8000/api/summarize',
                    json={'content': content},
                    timeout=10
                )

                if response.status_code == 200:
                    summary = response.json().get('summary', '')

                    # DB ì—…ë°ì´íŠ¸
                    cursor.execute("""
                        UPDATE news_articles
                        SET ai_summary = %s
                        WHERE id = %s
                    """, (summary, article_id))

                    summarized_count += 1

            except Exception as e:
                logger.error(f"âŒ ê¸°ì‚¬ ID {article_id} ìš”ì•½ ì‹¤íŒ¨: {e}")
                continue

        conn.commit()
        cursor.close()
        conn.close()

        logger.info(f"âœ… ìš”ì•½ ì™„ë£Œ: {summarized_count}/{len(articles)}ê°œ")
        return f"summarized_{summarized_count}"

    except Exception as e:
        logger.error(f"âŒ ìš”ì•½ ì‹¤íŒ¨: {e}")
        raise

# Task ì •ì˜
check_task = PythonOperator(
    task_id='check_raw_articles',
    python_callable=check_raw_articles,
    dag=dag,
)

process_task = PythonOperator(
    task_id='process_raw_articles',
    python_callable=process_articles,
    dag=dag,
)

summarize_task = PythonOperator(
    task_id='summarize_articles',
    python_callable=summarize_articles,
    dag=dag,
)

# Task ìˆœì„œ: í™•ì¸ -> ì²˜ë¦¬ -> ìš”ì•½
check_task >> process_task >> summarize_task

# ===== ì£¼ì„ ì²˜ë¦¬ ë =====
'''
