import 'reflect-metadata';
import dotenv from 'dotenv';

// í™˜ê²½ë³€ìˆ˜ ë¨¼ì € ë¡œë“œ (docker-composeì˜ env_fileì´ ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ .env)
dotenv.config();

import express from 'express';
import cors from 'cors';
import { AppDataSource } from './config/database';
import { newsCrawlerService } from './services/newsCrawlerService';
import logger from './config/logger';

const app = express();
const PORT = parseInt(process.env.API_CRAWLER_PORT || '4003', 10);

app.use(cors());
app.use(express.json());

// í—¬ìŠ¤ì²´í¬
app.get('/health', (req, res) => {
  res.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    service: 'FANS API Crawler Service'
  });
});

// API í¬ë¡¤ë§ ì‹œì‘
app.post('/crawl/start', async (req, res) => {
  try {
    logger.info('Request body:', req.body);
    const limit = Number(req.body?.limit) || 5; // ê¸°ë³¸ê°’ 5
    logger.info(`ğŸ“° API í¬ë¡¤ë§ ì‹œì‘... (ì¹´í…Œê³ ë¦¬ë‹¹ ${limit}ê°œ)`);
    const results = await newsCrawlerService.crawlAllCategories(limit);

    let totalCollected = 0;
    const summary: string[] = [];

    for (const [category, articles] of Object.entries(results)) {
      totalCollected += articles.length;
      summary.push(`${category}: ${articles.length}ê°œ`);
    }

    res.json({
      message: 'API í¬ë¡¤ë§ ì™„ë£Œ',
      totalCollected,
      results: summary,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    logger.error('API í¬ë¡¤ë§ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'API í¬ë¡¤ë§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤' });
  }
});

// ì§€ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ ì¡°íšŒ
app.get('/categories', (req, res) => {
  res.json({
    supportedCategories: newsCrawlerService.getSupportedCategories(),
    timestamp: new Date().toISOString()
  });
});

// ê¸°ì¡´ ê¸°ì‚¬ í¸í–¥ì„± ë¶„ì„ (ë¶„ì„ ì•ˆëœ ê¸°ì‚¬ë“¤)
app.post('/analyze/backfill', async (req, res) => {
  try {
    const limit = Number(req.body?.limit) || 100; // ê¸°ë³¸ê°’ 100ê°œì”©
    logger.info(`ğŸ“Š ê¸°ì¡´ ê¸°ì‚¬ í¸í–¥ì„± ë¶„ì„ ì‹œì‘... (ìµœëŒ€ ${limit}ê°œ)`);

    const result = await newsCrawlerService.analyzeExistingArticles(limit);

    res.json({
      message: 'ê¸°ì¡´ ê¸°ì‚¬ ë¶„ì„ ì™„ë£Œ',
      ...result,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    logger.error('ê¸°ì¡´ ê¸°ì‚¬ ë¶„ì„ ì‹¤íŒ¨:', error);
    res.status(500).json({ error: 'ê¸°ì¡´ ê¸°ì‚¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤' });
  }
});

// í¬ë¡¤ëŸ¬ ìƒíƒœ ì¡°íšŒ
app.get('/status', (_req, res) => {
  res.json({
    status: 'running',
    supportedCategories: newsCrawlerService.getSupportedCategories(),
    endpoints: [
      'POST /crawl/start - API í¬ë¡¤ë§ ì‹œì‘',
      'POST /analyze/backfill - ê¸°ì¡´ ê¸°ì‚¬ í¸í–¥ì„± ë¶„ì„',
      'GET /categories - ì§€ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬ ëª©ë¡',
      'GET /health - í—¬ìŠ¤ì²´í¬'
    ],
    timestamp: new Date().toISOString()
  });
});

async function startServer() {
  try {
    await AppDataSource.initialize();
    logger.info('âœ… Database connected successfully');

    app.listen(PORT, '0.0.0.0', () => {
      logger.info(`ğŸš€ API Crawler Service running on port ${PORT}`);
      logger.info(`ğŸ“Š Health check: http://localhost:${PORT}/health`);
      logger.info(`ğŸ“° API crawl: POST http://localhost:${PORT}/crawl/start`);
      logger.info(`ğŸ“‹ API categories: GET http://localhost:${PORT}/categories`);
    });
  } catch (error) {
    logger.error('âŒ Failed to start API crawler service:', error);
    process.exit(1);
  }
}

startServer();