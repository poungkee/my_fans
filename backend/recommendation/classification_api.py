"""
‚ö†Ô∏è Ïù¥ ÌååÏùºÏùÄ Îçî Ïù¥ÏÉÅ ÏÇ¨Ïö©ÎêòÏßÄ ÏïäÏäµÎãàÎã§ ‚ö†Ô∏è

Spark ML API ‚Üí Simple Classifier API(backend/simple-classifier)Î°ú ÎåÄÏ≤¥Îê®

Ïã§Ï†úÎ°ú Ïù¥ APIÎèÑ Spark MLÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÍ≥† ÏûàÏóàÏäµÎãàÎã§ (286Ï§Ñ Ï∞∏Ï°∞).
ÏõêÎ≥∏ Ïπ¥ÌÖåÍ≥†Î¶¨Î•º Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©ÌïòÎäî Î∞©ÏãùÏù¥ÏóàÏúºÎØÄÎ°ú,
Spark ÏùòÏ°¥ÏÑ±Îßå Ï†úÍ±∞Ìïú Í≤ΩÎüâ Î≤ÑÏ†ÑÏúºÎ°ú ÎåÄÏ≤¥ÌñàÏäµÎãàÎã§.

ÏïÑÎûò ÏΩîÎìúÎäî Ï∞∏Í≥†Ïö©ÏúºÎ°ú Ï£ºÏÑù Ï≤òÎ¶¨ÎêòÏóàÏäµÎãàÎã§.
ÌïÑÏöî Ïãú Î≥µÍµ¨ Í∞ÄÎä•ÌïòÎèÑÎ°ù ÏΩîÎìúÎ•º ÏÇ≠Ï†úÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§.
"""

'''
# ===== ÏïÑÎûò ÏΩîÎìúÎäî Ï£ºÏÑù Ï≤òÎ¶¨Îê® (Spark ÎåÄÏ≤¥) =====

"""
Spark ML Ïπ¥ÌÖåÍ≥†Î¶¨ Î∂ÑÎ•ò API ÏÑúÎπÑÏä§
ÌÅ¨Î°§Îü¨Í∞Ä Ìò∏Ï∂úÌï† Ïàò ÏûàÎäî REST API Ï†úÍ≥µ
"""

from flask import Flask, request, jsonify
from pyspark.sql import SparkSession
from category_classifier import CategoryClassifier
import logging
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Spark ÏÑ∏ÏÖò Ï†ÑÏó≠ Î≥ÄÏàò
spark = None
classifier = None

def init_spark():
    """Spark ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî"""
    global spark, classifier

    if spark is None:
        logger.info("üöÄ Spark ÏÑ∏ÏÖò Ï¥àÍ∏∞Ìôî Ï§ë...")
        # Use local mode to avoid distributed filesystem issues
        spark = SparkSession.builder \
            .appName("CategoryClassificationAPI") \
            .master("local[*]") \
            .config("spark.driver.memory", "2g") \
            .config("spark.sql.shuffle.partitions", "4") \
            .getOrCreate()

        logger.info("‚úÖ Spark ÏÑ∏ÏÖò ÏÉùÏÑ± ÏôÑÎ£å")

        # Î∂ÑÎ•òÍ∏∞ Ï¥àÍ∏∞Ìôî
        classifier = CategoryClassifier(spark)

        # Î™®Îç∏ Î°úÎìú ÎòêÎäî ÌïôÏäµ
        if not classifier.load_model():
            logger.info("üéì Î™®Îç∏Ïù¥ ÏóÜÏñ¥ÏÑú ÌïôÏäµÌï©ÎãàÎã§...")
            classifier.train_model()
        else:
            logger.info("‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å")

@app.route('/health', methods=['GET'])
def health_check():
    """Ìó¨Ïä§ Ï≤¥ÌÅ¨"""
    return jsonify({
        'status': 'healthy',
        'service': 'Spark ML Classification API',
        'spark_active': spark is not None
    })

@app.route('/classify', methods=['POST'])
def classify_news():
    """
    Îâ¥Ïä§ Ïπ¥ÌÖåÍ≥†Î¶¨ Î∂ÑÎ•ò

    Request Body:
    {
        "title": "Í∏∞ÏÇ¨ Ï†úÎ™©",
        "content": "Í∏∞ÏÇ¨ Î≥∏Î¨∏"
    }

    Response:
    {
        "category_name": "Í≤ΩÏ†ú",
        "category_id": 2,
        "confidence": 0.85
    }
    """
    try:
        data = request.get_json()

        if not data:
            return jsonify({'error': 'No JSON data provided'}), 400

        title = data.get('title', '')
        content = data.get('content', '')

        if not title and not content:
            return jsonify({'error': 'Title or content required'}), 400

        logger.info(f"üì∞ Î∂ÑÎ•ò ÏöîÏ≤≠: {title[:50]}...")

        # Î∂ÑÎ•ò ÏàòÌñâ
        category_name, category_id, confidence = classifier.predict(title, content)

        logger.info(f"‚úÖ Î∂ÑÎ•ò ÏôÑÎ£å: {category_name} (Ïã†Î¢∞ÎèÑ: {confidence:.2f})")

        return jsonify({
            'category_name': category_name,
            'category_id': category_id,
            'confidence': confidence,
            'success': True
        })

    except Exception as e:
        logger.error(f"‚ùå Î∂ÑÎ•ò Ïã§Ìå®: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'success': False
        }), 500

@app.route('/batch-classify', methods=['POST'])
def batch_classify():
    """
    Ïó¨Îü¨ Îâ¥Ïä§ ÎèôÏãú Î∂ÑÎ•ò

    Request Body:
    {
        "articles": [
            {"title": "Ï†úÎ™©1", "content": "Î≥∏Î¨∏1"},
            {"title": "Ï†úÎ™©2", "content": "Î≥∏Î¨∏2"}
        ]
    }
    """
    try:
        data = request.get_json()
        articles = data.get('articles', [])

        if not articles:
            return jsonify({'error': 'No articles provided'}), 400

        logger.info(f"üìö Î∞∞Ïπò Î∂ÑÎ•ò ÏöîÏ≤≠: {len(articles)}Í∞ú Í∏∞ÏÇ¨")

        results = []
        for article in articles:
            title = article.get('title', '')
            content = article.get('content', '')

            try:
                category_name, category_id, confidence = classifier.predict(title, content)
                results.append({
                    'category_name': category_name,
                    'category_id': category_id,
                    'confidence': confidence,
                    'success': True
                })
            except Exception as e:
                logger.error(f"‚ùå Í∏∞ÏÇ¨ Î∂ÑÎ•ò Ïã§Ìå®: {e}")
                results.append({
                    'error': str(e),
                    'success': False
                })

        logger.info(f"‚úÖ Î∞∞Ïπò Î∂ÑÎ•ò ÏôÑÎ£å: {len(results)}Í∞ú")

        return jsonify({
            'results': results,
            'total': len(results),
            'success': True
        })

    except Exception as e:
        logger.error(f"‚ùå Î∞∞Ïπò Î∂ÑÎ•ò Ïã§Ìå®: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'success': False
        }), 500

@app.route('/retrain', methods=['POST'])
def retrain_model():
    """Î™®Îç∏ Ïû¨ÌïôÏäµ"""
    try:
        logger.info("üéì Î™®Îç∏ Ïû¨ÌïôÏäµ ÏãúÏûë...")
        classifier.train_model()
        logger.info("‚úÖ Î™®Îç∏ Ïû¨ÌïôÏäµ ÏôÑÎ£å")

        return jsonify({
            'message': 'Model retrained successfully',
            'success': True
        })
    except Exception as e:
        logger.error(f"‚ùå Ïû¨ÌïôÏäµ Ïã§Ìå®: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'success': False
        }), 500

def get_db_connection():
    """PostgreSQL Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞"""
    return psycopg2.connect(
        host=os.getenv('DB_HOST', 'postgres'),
        port=int(os.getenv('DB_PORT', 5432)),
        user=os.getenv('POSTGRES_USER', 'fans_user'),
        password=os.getenv('POSTGRES_PASSWORD', 'fans_password'),
        database=os.getenv('POSTGRES_DB', 'fans_db')
    )

# Ïñ∏Î°†ÏÇ¨ Îß§Ìïë
SOURCE_MAP = {
    'Ïó∞Ìï©Îâ¥Ïä§': 1, 'ÎèôÏïÑÏùºÎ≥¥': 20, 'Î¨∏ÌôîÏùºÎ≥¥': 21,
    'ÏÑ∏Í≥ÑÏùºÎ≥¥': 22, 'Ï°∞ÏÑ†ÏùºÎ≥¥': 23, 'Ï§ëÏïôÏùºÎ≥¥': 25,
    'ÌïúÍ≤®Î†à': 28, 'Í≤ΩÌñ•Ïã†Î¨∏': 32, 'ÌïúÍµ≠ÏùºÎ≥¥': 55,
    'Îß§ÏùºÍ≤ΩÏ†ú': 56, 'ÌïúÍµ≠Í≤ΩÏ†ú': 214, 'Î®∏ÎãàÌà¨Îç∞Ïù¥': 421,
    'YTN': 437, 'JTBC': 448,
    'Í∏∞ÌÉÄ': 449
}

def classify_source(original_source):
    """Ïñ∏Î°†ÏÇ¨ ÌÖçÏä§Ìä∏Î•º source_idÎ°ú Îß§Ìïë"""
    if not original_source:
        return 449  # Í∏∞ÌÉÄ

    # ÏôÑÏ†Ñ ÏùºÏπò Í≤ÄÏÉâ
    if original_source in SOURCE_MAP:
        return SOURCE_MAP[original_source]

    # Î∂ÄÎ∂Ñ ÏùºÏπò Í≤ÄÏÉâ
    for source_name, source_id in SOURCE_MAP.items():
        if source_name in original_source or original_source in source_name:
            return source_id

    return 449  # Í∏∞ÌÉÄ

@app.route('/process-raw-news', methods=['POST'])
def process_raw_news():
    """
    raw_news_articlesÏóêÏÑú ÎØ∏Ï≤òÎ¶¨ Í∏∞ÏÇ¨Î•º ÏùΩÏñ¥ÏÑú Î∂ÑÎ•òÌïòÍ≥† news_articlesÎ°ú Ïù¥Îèô

    Request Body (ÏÑ†ÌÉùÏ†Å):
    {
        "limit": 100  # Ìïú Î≤àÏóê Ï≤òÎ¶¨Ìï† Í∏∞ÏÇ¨ Ïàò (Í∏∞Î≥∏Í∞í: 50)
    }
    """
    try:
        data = request.get_json() or {}
        limit = data.get('limit', 50)

        logger.info(f"üîÑ ÏõêÎ≥∏ Í∏∞ÏÇ¨ Ï≤òÎ¶¨ ÏãúÏûë (ÏµúÎåÄ {limit}Í∞ú)...")

        conn = get_db_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        # ÎØ∏Ï≤òÎ¶¨ raw Í∏∞ÏÇ¨ Ï°∞Ìöå
        cursor.execute("""
            SELECT id, title, content, url, image_url, journalist, pub_date,
                   original_source, original_category
            FROM raw_news_articles
            WHERE processed = FALSE
            ORDER BY created_at ASC
            LIMIT %s
        """, (limit,))

        raw_articles = cursor.fetchall()

        if not raw_articles:
            logger.info("‚úÖ Ï≤òÎ¶¨Ìï† ÏõêÎ≥∏ Í∏∞ÏÇ¨Í∞Ä ÏóÜÏäµÎãàÎã§")
            cursor.close()
            conn.close()
            return jsonify({
                'message': 'No raw articles to process',
                'processed': 0,
                'success': True
            })

        logger.info(f"üìö {len(raw_articles)}Í∞ú ÏõêÎ≥∏ Í∏∞ÏÇ¨ Ï≤òÎ¶¨ Ï§ë...")

        processed_count = 0
        failed_count = 0

        # Ïπ¥ÌÖåÍ≥†Î¶¨ ID Îß§Ìïë
        category_map = {
            'Ï†ïÏπò': 1,
            'Í≤ΩÏ†ú': 2,
            'ÏÇ¨Ìöå': 3,
            'ÏÉùÌôú/Î¨∏Ìôî': 4,
            'IT/Í≥ºÌïô': 5,
            'ÏÑ∏Í≥Ñ': 6,
            'Ïä§Ìè¨Ï∏†': 7,
            'Ïó∞Ïòà': 8
        }

        for raw_article in raw_articles:
            try:
                # Spark ML ÏÇ¨Ïö© ÏïàÌï®! Í∏∞ÏÇ¨ ÌéòÏù¥ÏßÄÏóêÏÑú ÌååÏã±Ìïú ÏõêÎ≥∏ Ïπ¥ÌÖåÍ≥†Î¶¨ ÏÇ¨Ïö©
                original_category = raw_article['original_category'] or 'ÏÇ¨Ìöå'
                category_id = category_map.get(original_category, 3)  # Í∏∞Î≥∏Í∞í: ÏÇ¨Ìöå(3)

                # Ïñ∏Î°†ÏÇ¨ Î∂ÑÎ•ò
                source_id = classify_source(raw_article['original_source'])

                logger.info(f"‚úÖ Ïπ¥ÌÖåÍ≥†Î¶¨ ÌôïÏ†ï: {raw_article['title'][:50]}... -> {original_category} (Ïñ∏Î°†ÏÇ¨: {source_id})")

                # news_articlesÏóê ÏÇΩÏûÖ
                cursor.execute("""
                    INSERT INTO news_articles
                    (title, content, url, image_url, journalist, pub_date, source_id, category_id)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (url) DO NOTHING
                """, (
                    raw_article['title'],
                    raw_article['content'],
                    raw_article['url'],
                    raw_article['image_url'],
                    raw_article['journalist'],
                    raw_article['pub_date'],
                    source_id,
                    category_id
                ))

                # raw_news_articles ÏÉÅÌÉú ÏóÖÎç∞Ïù¥Ìä∏
                cursor.execute("""
                    UPDATE raw_news_articles
                    SET processed = TRUE, processed_at = %s
                    WHERE id = %s
                """, (datetime.now(), raw_article['id']))

                processed_count += 1

            except Exception as e:
                logger.error(f"‚ùå Í∏∞ÏÇ¨ Ï≤òÎ¶¨ Ïã§Ìå® (ID: {raw_article['id']}): {e}")

                # ÏóêÎü¨ Í∏∞Î°ù
                cursor.execute("""
                    UPDATE raw_news_articles
                    SET processing_error = %s
                    WHERE id = %s
                """, (str(e), raw_article['id']))

                failed_count += 1

        conn.commit()
        cursor.close()
        conn.close()

        logger.info(f"‚úÖ Ï≤òÎ¶¨ ÏôÑÎ£å: {processed_count}Í∞ú ÏÑ±Í≥µ, {failed_count}Í∞ú Ïã§Ìå®")

        return jsonify({
            'message': f'Processed {processed_count} articles successfully',
            'processed': processed_count,
            'failed': failed_count,
            'total': len(raw_articles),
            'success': True
        })

    except Exception as e:
        logger.error(f"‚ùå ÏõêÎ≥∏ Í∏∞ÏÇ¨ Ï≤òÎ¶¨ Ïã§Ìå®: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'success': False
        }), 500

if __name__ == '__main__':
    # Spark Ï¥àÍ∏∞Ìôî
    init_spark()

    # Flask ÏÑúÎ≤Ñ ÏãúÏûë
    port = int(os.getenv('CLASSIFICATION_API_PORT', 5000))
    logger.info(f"üåê Classification API ÏÑúÎ≤Ñ ÏãúÏûë: Ìè¨Ìä∏ {port}")
    app.run(host='0.0.0.0', port=port, debug=False)

# ===== Ï£ºÏÑù Ï≤òÎ¶¨ ÎÅù =====
'''
