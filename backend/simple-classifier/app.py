"""
ê°„ë‹¨í•œ ë‰´ìŠ¤ ë¶„ë¥˜ API (Spark ëŒ€ì²´)
Spark ML ì—†ì´ Flaskë¡œë§Œ êµ¬í˜„
"""

from flask import Flask, request, jsonify
import logging
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

def get_db_connection():
    """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    return psycopg2.connect(
        host=os.getenv('DB_HOST', 'postgres'),
        port=int(os.getenv('DB_PORT', 5432)),
        user=os.getenv('POSTGRES_USER', 'fans_user'),
        password=os.getenv('POSTGRES_PASSWORD', 'fans_password'),
        database=os.getenv('POSTGRES_DB', 'fans_db')
    )

# ì–¸ë¡ ì‚¬ ë§¤í•‘
SOURCE_MAP = {
    'ì—°í•©ë‰´ìŠ¤': 1, 'ë™ì•„ì¼ë³´': 20, 'ë¬¸í™”ì¼ë³´': 21,
    'ì„¸ê³„ì¼ë³´': 22, 'ì¡°ì„ ì¼ë³´': 23, 'ì¤‘ì•™ì¼ë³´': 25,
    'í•œê²¨ë ˆ': 28, 'ê²½í–¥ì‹ ë¬¸': 32, 'í•œêµ­ì¼ë³´': 55,
    'ë§¤ì¼ê²½ì œ': 56, 'í•œêµ­ê²½ì œ': 214, 'ë¨¸ë‹ˆíˆ¬ë°ì´': 421,
    'YTN': 437, 'JTBC': 448,
    'ê¸°íƒ€': 449
}

def classify_source(original_source):
    """ì–¸ë¡ ì‚¬ í…ìŠ¤íŠ¸ë¥¼ source_idë¡œ ë§¤í•‘"""
    if not original_source:
        return 449  # ê¸°íƒ€

    # ì™„ì „ ì¼ì¹˜ ê²€ìƒ‰
    if original_source in SOURCE_MAP:
        return SOURCE_MAP[original_source]

    # ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
    for source_name, source_id in SOURCE_MAP.items():
        if source_name in original_source or original_source in source_name:
            return source_id

    return 449  # ê¸°íƒ€

@app.route('/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        'status': 'healthy',
        'service': 'Simple Classification API (No Spark)',
    })

@app.route('/process-raw-news', methods=['POST'])
def process_raw_news():
    """
    raw_news_articlesì—ì„œ ë¯¸ì²˜ë¦¬ ê¸°ì‚¬ë¥¼ ì½ì–´ì„œ ë¶„ë¥˜í•˜ê³  news_articlesë¡œ ì´ë™

    âš ï¸ Spark ML ì‚¬ìš© ì•ˆí•¨! ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ íŒŒì‹±í•œ ì›ë³¸ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©

    Request Body (ì„ íƒì ):
    {
        "limit": 100  # í•œ ë²ˆì— ì²˜ë¦¬í•  ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ê°’: 50)
    }
    """
    try:
        data = request.get_json() or {}
        limit = data.get('limit', 50)

        logger.info(f"ğŸ”„ ì›ë³¸ ê¸°ì‚¬ ì²˜ë¦¬ ì‹œì‘ (ìµœëŒ€ {limit}ê°œ)...")

        conn = get_db_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        # ë¯¸ì²˜ë¦¬ raw ê¸°ì‚¬ ì¡°íšŒ
        cursor.execute("""
            SELECT id, title, content, url, image_url, journalist, pub_date,
                   original_source, original_category
            FROM raw_news_articles
            WHERE processed = FALSE
            ORDER BY created_at ASC
            LIMIT %s
        """, (limit,))

        raw_articles = cursor.fetchall()

        if not raw_articles:
            logger.info("âœ… ì²˜ë¦¬í•  ì›ë³¸ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤")
            cursor.close()
            conn.close()
            return jsonify({
                'message': 'No raw articles to process',
                'processed': 0,
                'success': True
            })

        logger.info(f"ğŸ“š {len(raw_articles)}ê°œ ì›ë³¸ ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘...")

        processed_count = 0
        failed_count = 0

        # ì¹´í…Œê³ ë¦¬ ID ë§¤í•‘
        category_map = {
            'ì •ì¹˜': 1,
            'ê²½ì œ': 2,
            'ì‚¬íšŒ': 3,
            'ìƒí™œ/ë¬¸í™”': 4,
            'IT/ê³¼í•™': 5,
            'ì„¸ê³„': 6,
            'ìŠ¤í¬ì¸ ': 7,
            'ì—°ì˜ˆ': 8
        }

        for raw_article in raw_articles:
            try:
                # âš ï¸ Spark ML ì‚¬ìš© ì•ˆí•¨! ê¸°ì‚¬ í˜ì´ì§€ì—ì„œ íŒŒì‹±í•œ ì›ë³¸ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
                original_category = raw_article['original_category'] or 'ì‚¬íšŒ'
                category_id = category_map.get(original_category, 3)  # ê¸°ë³¸ê°’: ì‚¬íšŒ(3)

                # ì–¸ë¡ ì‚¬ ë¶„ë¥˜
                source_id = classify_source(raw_article['original_source'])

                logger.info(f"âœ… ì¹´í…Œê³ ë¦¬ í™•ì •: {raw_article['title'][:50]}... -> {original_category} (ì–¸ë¡ ì‚¬: {source_id})")

                # news_articlesì— ì‚½ì…
                cursor.execute("""
                    INSERT INTO news_articles
                    (title, content, url, image_url, journalist, pub_date, source_id, category_id)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (url) DO NOTHING
                """, (
                    raw_article['title'],
                    raw_article['content'],
                    raw_article['url'],
                    raw_article['image_url'],
                    raw_article['journalist'],
                    raw_article['pub_date'],
                    source_id,
                    category_id
                ))

                # raw_news_articles ìƒíƒœ ì—…ë°ì´íŠ¸
                cursor.execute("""
                    UPDATE raw_news_articles
                    SET processed = TRUE, processed_at = %s
                    WHERE id = %s
                """, (datetime.now(), raw_article['id']))

                processed_count += 1

            except Exception as e:
                logger.error(f"âŒ ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨ (ID: {raw_article['id']}): {e}")

                # ì—ëŸ¬ ê¸°ë¡
                cursor.execute("""
                    UPDATE raw_news_articles
                    SET processing_error = %s
                    WHERE id = %s
                """, (str(e), raw_article['id']))

                failed_count += 1

        conn.commit()
        cursor.close()
        conn.close()

        logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ ì„±ê³µ, {failed_count}ê°œ ì‹¤íŒ¨")

        return jsonify({
            'message': f'Processed {processed_count} articles successfully',
            'processed': processed_count,
            'failed': failed_count,
            'total': len(raw_articles),
            'success': True
        })

    except Exception as e:
        logger.error(f"âŒ ì›ë³¸ ê¸°ì‚¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        return jsonify({
            'error': str(e),
            'success': False
        }), 500

if __name__ == '__main__':
    port = int(os.getenv('CLASSIFICATION_API_PORT', 5000))
    logger.info(f"ğŸŒ Simple Classification API ì„œë²„ ì‹œì‘: í¬íŠ¸ {port}")
    logger.info("âš ï¸  Spark ML ì‚¬ìš© ì•ˆí•¨ - ì›ë³¸ ì¹´í…Œê³ ë¦¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©")
    app.run(host='0.0.0.0', port=port, debug=False)
